{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8213645,"sourceType":"datasetVersion","datasetId":4868036}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/eyamethnani/pcd-model?scriptVersionId=175151273\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport numpy as np\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:31:42.01111Z","iopub.execute_input":"2024-05-01T21:31:42.012035Z","iopub.status.idle":"2024-05-01T21:31:42.01757Z","shell.execute_reply.started":"2024-05-01T21:31:42.012003Z","shell.execute_reply":"2024-05-01T21:31:42.016389Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndata_path = '/kaggle/input/data-feat-clean/data_new_features_cleaned (1).csv'\ndata = pd.read_csv(data_path)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:31:44.337162Z","iopub.execute_input":"2024-05-01T21:31:44.338039Z","iopub.status.idle":"2024-05-01T21:31:44.422209Z","shell.execute_reply.started":"2024-05-01T21:31:44.338003Z","shell.execute_reply":"2024-05-01T21:31:44.421393Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:13:21.427307Z","iopub.execute_input":"2024-04-28T14:13:21.427902Z","iopub.status.idle":"2024-04-28T14:13:34.178374Z","shell.execute_reply.started":"2024-04-28T14:13:21.427873Z","shell.execute_reply":"2024-04-28T14:13:34.177204Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install virtualenv\n!virtualenv venv\n!source venv/bin/activate\n!pip install package_name\n!pip install accelerate -U\n\n!pip install transformers[torch]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:13:34.180528Z","iopub.execute_input":"2024-04-28T14:13:34.180881Z","iopub.status.idle":"2024-04-28T14:14:28.094538Z","shell.execute_reply.started":"2024-04-28T14:13:34.180851Z","shell.execute_reply":"2024-04-28T14:14:28.091454Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: virtualenv in /opt/conda/lib/python3.10/site-packages (20.21.0)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv) (0.3.8)\nRequirement already satisfied: filelock<4,>=3.4.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv) (3.13.1)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv) (3.11.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"created virtual environment CPython3.10.13.final.0-64 in 294ms\n  creator CPython3Posix(dest=/kaggle/working/venv, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n    added seed packages: pip==23.0.1, setuptools==67.4.0, wheel==0.38.4\n  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: package_name in /opt/conda/lib/python3.10/site-packages (0.1)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import load_dataset, Dataset\n\n\ndef is_about_animal_disease(text, state):\n    if state == 'yes event':\n        return True\n    else:\n        return False\n\n# Use apply with a lambda function to create the 'labels' column based on the 'is_about_animal_disease' function\ndata['labels'] = data.apply(lambda row: is_about_animal_disease(row['TEXT_filtered'], row['STATE']), axis=1).astype(int)\n\nfrom sklearn.model_selection import train_test_split\n\n\n# Split the DataFrame into training and evaluation sets\ntrain_df, eval_df = train_test_split(data, test_size=0.2, random_state=42)\n\n# Convert the DataFrame into datasets.Dataset format\ntrain_dataset = Dataset.from_pandas(train_df)\neval_dataset = Dataset.from_pandas(eval_df)\n\n\n# Initialize tokenizer and model\nmodel_name = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n# Tokenize the dataset and include labels\ndef tokenize_function(examples):\n    # Tokenize the text\n    tokenized_text = tokenizer(\n        examples[\"TEXT_filtered\"],\n        padding='max_length',\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n\n    # Include the labels in the returned dictionary\n    return {\n        \"input_ids\": tokenized_text[\"input_ids\"].squeeze(),\n        \"attention_mask\": tokenized_text[\"attention_mask\"].squeeze(),\n        \"labels\": examples[\"labels\"]\n    }\n\ntokenized_datasets = train_dataset.map(tokenize_function, batched=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:08:23.519395Z","iopub.execute_input":"2024-04-28T17:08:23.520133Z","iopub.status.idle":"2024-04-28T17:08:42.857755Z","shell.execute_reply.started":"2024-04-28T17:08:23.520101Z","shell.execute_reply":"2024-04-28T17:08:42.856846Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-04-28 17:08:28.731752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 17:08:28.731856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 17:08:28.866274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"311e0e2e5c384bdfbc6c17b089a5b492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"665c89058a0e4b0da6b43850bcaa0e6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8a12daeefe84cb2aadbd5d47a313d8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b7253fdabf45c2b565abc87aca6611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aafdbcefe6f348728ebe7e690a91f0e8"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/464 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bdb6336cac24d67a675079328a59224"}},"metadata":{}}]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/content/drive/MyDrive/web scraping/PCD/output directory\",\n    per_device_train_batch_size=4,\n    num_train_epochs=10,\n    logging_dir=\"/content/drive/MyDrive/web scraping/PCD/logging\",\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets,\n    tokenizer=tokenizer,\n)\n\n# Train the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:08:47.144569Z","iopub.execute_input":"2024-04-28T17:08:47.145723Z","iopub.status.idle":"2024-04-28T17:14:11.925572Z","shell.execute_reply.started":"2024-04-28T17:08:47.145679Z","shell.execute_reply":"2024-04-28T17:14:11.924698Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning:\n\nPassing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240428_170901-tu34yulq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/methnanieya14/huggingface/runs/tu34yulq' target=\"_blank\">genial-forest-7</a></strong> to <a href='https://wandb.ai/methnanieya14/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/methnanieya14/huggingface' target=\"_blank\">https://wandb.ai/methnanieya14/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/methnanieya14/huggingface/runs/tu34yulq' target=\"_blank\">https://wandb.ai/methnanieya14/huggingface/runs/tu34yulq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1160' max='1160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1160/1160 04:52, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.304300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.030500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1160, training_loss=0.1475330256182572, metrics={'train_runtime': 323.4421, 'train_samples_per_second': 14.346, 'train_steps_per_second': 3.586, 'total_flos': 1220835296870400.0, 'train_loss': 0.1475330256182572, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenize and preprocess the evaluation dataset\ntokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n\n# Evaluate the model\neval_results = trainer.evaluate(eval_dataset=tokenized_eval_dataset)\nprint(eval_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:15:47.124158Z","iopub.execute_input":"2024-04-28T17:15:47.124864Z","iopub.status.idle":"2024-04-28T17:15:49.378988Z","shell.execute_reply.started":"2024-04-28T17:15:47.124832Z","shell.execute_reply":"2024-04-28T17:15:49.378056Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/117 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfdd27f454c54d0eb5c9cead01eaea49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.11063043773174286, 'eval_runtime': 2.0928, 'eval_samples_per_second': 55.905, 'eval_steps_per_second': 7.167, 'epoch': 10.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\neval_predictions = trainer.predict(tokenized_eval_dataset)\n\n# Extract predicted labels and true labels\npredicted_labels = eval_predictions.predictions.argmax(axis=1)\ntrue_labels = tokenized_eval_dataset['labels']\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:15:51.256252Z","iopub.execute_input":"2024-04-28T17:15:51.256599Z","iopub.status.idle":"2024-04-28T17:15:53.399598Z","shell.execute_reply.started":"2024-04-28T17:15:51.256571Z","shell.execute_reply":"2024-04-28T17:15:53.398663Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n# Assuming eval_df is your evaluation DataFrame\n# Create a new DataFrame to store predictions, true labels, and text\nresults_df = pd.DataFrame({\n    'Text': eval_df['TEXT'],  # Assuming 'TEXT' is the column containing the text data\n    'True_Labels': true_labels,\n    'Predicted_Labels': predicted_labels\n})\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T17:32:30.446111Z","iopub.execute_input":"2024-04-28T17:32:30.446808Z","iopub.status.idle":"2024-04-28T17:32:30.461251Z","shell.execute_reply.started":"2024-04-28T17:32:30.446774Z","shell.execute_reply":"2024-04-28T17:32:30.460046Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"                                                  Text  True_Labels  \\\n576  first human case of west nile virus detected i...            1   \n278  confirmed outbreak of anthrax case in nigeriay...            1   \n104  extremely rare mosquitoborne virus found in al...            1   \n445  biological and toxin weapons are either microo...            0   \n432  washington horse positive for strangles a hors...            1   \n..                                                 ...          ...   \n301  seasonal influenza is an acute respiratory inf...            0   \n543  florida suwannee county horse is 11th eastern ...            1   \n298  around the age of 6 months an infants need for...            0   \n250  إنفلونزا الطيور تنتقل إلى قطط وسلطات كوريا الج...            1   \n77   proper infant nutrition is fundamental to a ch...            0   \n\n     Predicted_Labels  \n576                 1  \n278                 1  \n104                 1  \n445                 0  \n432                 1  \n..                ...  \n301                 0  \n543                 1  \n298                 0  \n250                 1  \n77                  0  \n\n[117 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Tokenize and preprocess the evaluation dataset\ntokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n\n# Get the predictions\n# Get the predictions\neval_predictions = trainer.predict(tokenized_eval_dataset)\npredicted_labels = np.argmax(eval_predictions.predictions, axis=1)\ntrue_labels = tokenized_eval_dataset['labels']\n\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-event', 'Event'], yticklabels=['Non-event', 'Event'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:20:58.81966Z","iopub.execute_input":"2024-04-28T14:20:58.820378Z","iopub.status.idle":"2024-04-28T14:21:01.419234Z","shell.execute_reply.started":"2024-04-28T14:20:58.820347Z","shell.execute_reply":"2024-04-28T14:21:01.417395Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/117 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5eea574b8554a95b8ee870073c537b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Calculate the accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:21:10.190069Z","iopub.execute_input":"2024-04-28T14:21:10.191009Z","iopub.status.idle":"2024-04-28T14:21:10.199992Z","shell.execute_reply.started":"2024-04-28T14:21:10.190962Z","shell.execute_reply":"2024-04-28T14:21:10.198661Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Accuracy: 0.9658119658119658\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:21:14.48503Z","iopub.execute_input":"2024-04-28T14:21:14.485407Z","iopub.status.idle":"2024-04-28T14:21:14.491767Z","shell.execute_reply.started":"2024-04-28T14:21:14.485375Z","shell.execute_reply":"2024-04-28T14:21:14.490445Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true_labels, predicted_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:21:16.294937Z","iopub.execute_input":"2024-04-28T14:21:16.295732Z","iopub.status.idle":"2024-04-28T14:21:16.316821Z","shell.execute_reply.started":"2024-04-28T14:21:16.295699Z","shell.execute_reply":"2024-04-28T14:21:16.313641Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97        74\n           1       0.91      1.00      0.96        43\n\n    accuracy                           0.97       117\n   macro avg       0.96      0.97      0.96       117\nweighted avg       0.97      0.97      0.97       117\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# custom bert with new features\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom transformers import BertTokenizer, BertModel, Trainer, TrainingArguments\nfrom datasets import Dataset, load_dataset\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:33:06.937126Z","iopub.execute_input":"2024-05-01T21:33:06.938246Z","iopub.status.idle":"2024-05-01T21:33:22.716698Z","shell.execute_reply.started":"2024-05-01T21:33:06.938202Z","shell.execute_reply":"2024-05-01T21:33:22.715724Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-01 21:33:13.885449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-01 21:33:13.885552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-01 21:33:14.011137: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import StandardScaler\nimport ast\n\n# Normalize numerical features\nscaler = StandardScaler()\nnumerical_features = scaler.fit_transform(data[['char_count', 'word_count', 'avg_word_length', 'polarity', 'subjectivity']])\n\n\n# Convert string representation of dictionaries to actual dictionaries\ndata['POS_counts'] = data['POS_counts'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n# Now let's redefine the function to encode POS counts\ndef encode_pos_counts(pos_counts):\n    pos_columns = sorted(list(set(key for dic in data['POS_counts'] for key in dic.keys())))\n    return [pos_counts.get(col, 0) for col in pos_columns]\n\n# Apply the function to the POS_counts column\npos_features = np.array(data['POS_counts'].apply(encode_pos_counts).tolist())\n\n\n\n\n\n# Tokenize text data\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\ntokenized_data = tokenizer(data['TEXT_filtered'].tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n\n# Split the dataset\ntrain_indices, test_indices = train_test_split(range(len(data)), test_size=0.2, random_state=42)\n\n# Train data\ntrain_tokenized = {key: val[train_indices] for key, val in tokenized_data.items()}\ntrain_numerical_features = torch.tensor(numerical_features[train_indices], dtype=torch.float32)\ntrain_pos_features = torch.tensor(pos_features[train_indices], dtype=torch.float32)\ntrain_labels = torch.tensor(data.loc[train_indices, 'STATE_encoded'].values, dtype=torch.long)\n\n# Test data\ntest_tokenized = {key: val[test_indices] for key, val in tokenized_data.items()}\ntest_numerical_features = torch.tensor(numerical_features[test_indices], dtype=torch.float32)\ntest_pos_features = torch.tensor(pos_features[test_indices], dtype=torch.float32)\ntest_labels = torch.tensor(data.loc[test_indices, 'STATE_encoded'].values, dtype=torch.long)\n\n# Combine additional features\ntrain_additional_features = torch.cat((train_numerical_features, train_pos_features), dim=1)\ntest_additional_features = torch.cat((test_numerical_features, test_pos_features), dim=1)\n\n# Creating the datasets\nclass TextDataset(Dataset):\n    def __init__(self, input_ids, attention_mask, additional_features, labels):\n        self.input_ids = input_ids\n        self.attention_mask = attention_mask\n        self.additional_features = additional_features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_mask[idx],\n            'additional_features': self.additional_features[idx],\n            'labels': self.labels[idx]\n        }\n\ntrain_dataset = TextDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], train_additional_features, train_labels)\ntest_dataset = TextDataset(test_tokenized['input_ids'], test_tokenized['attention_mask'], test_additional_features, test_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Reduced from 16 to 8\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:33:31.94236Z","iopub.execute_input":"2024-05-01T21:33:31.943235Z","iopub.status.idle":"2024-05-01T21:33:33.121351Z","shell.execute_reply.started":"2024-05-01T21:33:31.943202Z","shell.execute_reply":"2024-05-01T21:33:33.120308Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nfrom transformers import AutoModel\n\nclass CustomBERTModel(nn.Module):\n    def __init__(self):\n        super(CustomBERTModel, self).__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n        self.classifier = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size + len(numerical_features[0]) + len(pos_features[0]), 512),\n            nn.ReLU(),\n            nn.Linear(512, 2)  # Assuming binary classification\n        )\n    \n    def forward(self, input_ids, attention_mask, additional_features):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        combined_features = torch.cat((pooled_output, additional_features), dim=1)\n        return self.classifier(combined_features)  # This is where logits are directly returned\n\n\n# Initialize model\nmodel = CustomBERTModel()\n\n# Training and evaluation code here (you can use a similar setup with Trainer or a custom training loop)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:33:46.742038Z","iopub.execute_input":"2024-05-01T21:33:46.742935Z","iopub.status.idle":"2024-05-01T21:33:49.65827Z","shell.execute_reply.started":"2024-05-01T21:33:46.742903Z","shell.execute_reply":"2024-05-01T21:33:49.657304Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb7c4d974a645e4b189c6690d90f951"}},"metadata":{}}]},{"cell_type":"code","source":"from torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CustomBERTModel().to(device)\noptimizer = AdamW(model.parameters(), lr=5e-5)\nloss_fn = CrossEntropyLoss()\n\n# Training function\ndef train(model, loader, accumulation_steps=4):\n    model.train()\n    total_loss = 0\n    optimizer.zero_grad()  # Move zero_grad() outside the inner loop\n\n    for i, batch in enumerate(loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        additional_features = batch['additional_features'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask, additional_features)\n        loss = loss_fn(outputs, labels) / accumulation_steps  # Normalize our loss (if averaged)\n        loss.backward()\n        \n        if (i + 1) % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        total_loss += loss.item() * accumulation_steps  # Undo the normalization\n\n    return total_loss / len(loader)\n\n\n# Run training\nfor epoch in range(3):  # Adjust epochs based on model performance and dataset size\n    train_loss = train(model, train_loader)\n    print(f\"Epoch {epoch + 1}, Loss: {train_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:33:52.619826Z","iopub.execute_input":"2024-05-01T21:33:52.620191Z","iopub.status.idle":"2024-05-01T21:35:06.104888Z","shell.execute_reply.started":"2024-05-01T21:33:52.620162Z","shell.execute_reply":"2024-05-01T21:35:06.103867Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.5221\nEpoch 2, Loss: 0.2040\nEpoch 3, Loss: 0.1565\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print dimensions to understand the current setup\nprint(\"Pooled output size:\", model.bert.pooler.dense.out_features)  # Typically 768 for BERT base\nprint(\"Additional features size:\", additional_features.shape[1])\n\n# Calculate expected input size to the classifier\nexpected_input_size = model.bert.pooler.dense.out_features + additional_features.shape[1]\nprint(\"Expected classifier input size:\", expected_input_size)\n\n# Compare this with your classifier's input dimension\nprint(\"Current classifier input size:\", model.classifier[0].in_features)  # Adjust indexing if your setup differs\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:42:40.716253Z","iopub.execute_input":"2024-04-28T14:42:40.717069Z","iopub.status.idle":"2024-04-28T14:42:40.726848Z","shell.execute_reply.started":"2024-04-28T14:42:40.717035Z","shell.execute_reply":"2024-04-28T14:42:40.725592Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Pooled output size: 768\nAdditional features size: 8\nExpected classifier input size: 776\nCurrent classifier input size: 791\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef evaluate(model, loader):\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            additional_features = batch['additional_features'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask, additional_features)\n            predictions = outputs.argmax(dim=1)\n            all_predictions.extend(predictions.cpu().numpy())  # Collect predictions\n            all_labels.extend(labels.cpu().numpy())  # Collect labels\n\n    return all_predictions, all_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:35:27.500384Z","iopub.execute_input":"2024-05-01T21:35:27.500737Z","iopub.status.idle":"2024-05-01T21:35:27.508233Z","shell.execute_reply.started":"2024-05-01T21:35:27.500711Z","shell.execute_reply":"2024-05-01T21:35:27.507133Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Assuming you have already defined and trained your model, and have the test_loader ready\nall_predictions, all_labels = evaluate(model, test_loader)\n\n# Print classification report\nprint(classification_report(all_labels, all_predictions, target_names=['Class1', 'Class2']))  # Adjust class names as necessary\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T21:35:32.47689Z","iopub.execute_input":"2024-05-01T21:35:32.47724Z","iopub.status.idle":"2024-05-01T21:35:34.460554Z","shell.execute_reply.started":"2024-05-01T21:35:32.477212Z","shell.execute_reply":"2024-05-01T21:35:34.459548Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n      Class1       0.97      0.97      0.97        74\n      Class2       0.95      0.95      0.95        43\n\n    accuracy                           0.97       117\n   macro avg       0.96      0.96      0.96       117\nweighted avg       0.97      0.97      0.97       117\n\n","output_type":"stream"}]}]}